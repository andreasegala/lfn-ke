{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T00:00:01.278911700Z",
     "start_time": "2024-01-24T00:00:01.274149600Z"
    }
   },
   "outputs": [],
   "source": [
    "import commons.graph\n",
    "import commons.parse\n",
    "import commons.scores\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preliminary steps\n",
    "#### Create a GraphMaker\n",
    "Specify the stopword list and the desired stemmer:\n",
    "- ```POR```: Porter Stemmer\n",
    "- ```SNO```: Snowball Stemmer (English)\n",
    "- ```LAN```: Lancaster Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T00:00:05.068394500Z",
     "start_time": "2024-01-24T00:00:04.556726600Z"
    }
   },
   "outputs": [],
   "source": [
    "gm = commons.graph.GraphMaker('resources/longStopwords.txt', 'LAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Create (or update) the list of allowed articles\n",
    "Set the minimum number of nodes for a graph to be considered and run the function.\n",
    "For the current dataset the file is already made for you, **no need to run it again**.\n",
    "This function is meant to be executed only the first time or if the dataset changes, e.g. some articles are added or removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_nodes = 5\n",
    "commons.parse.update_allowed_forbidden_files(gm, min_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Sample the articles\n",
    "There are 35403 allowed articles available for sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 5000\n",
    "parsed_articles = commons.parse.parse_and_sample(sample_size, gm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Set the run name\n",
    "You will find the results in ```experiments/run_name/```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T00:00:09.166646900Z",
     "start_time": "2024-01-24T00:00:09.163294900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_name = 'testRun-40000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Compute the centralities!\n",
    "The names for the centralities are:\n",
    "- ```PR```: PageRank centrality\n",
    "- ```CC```: Closeness Centrality\n",
    "- ```BC```: Betwenness centrality\n",
    "- ```LCC```: Local Clustering Coefficient\n",
    "\n",
    "For the approximation there is an integer flag:\n",
    "- ```0```: exact centrality\n",
    "- ```1```: approximated centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commons.scores.centrality_print_scores(parsed_articles, 'BC', 0, run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commons.scores.centrality_print_scores(parsed_articles, 'BC', 1, run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commons.scores.centrality_print_scores(parsed_articles, 'PR', 0, run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commons.scores.centrality_print_scores(parsed_articles, 'PR', 1, run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commons.scores.centrality_print_scores(parsed_articles, 'LCC', 0, run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commons.scores.centrality_print_scores(parsed_articles, 'LCC', 1, run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commons.scores.centrality_print_scores(parsed_articles, 'CC', 0, run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commons.scores.centrality_print_scores(parsed_articles, 'CC', 1, run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Look at the Results!\n",
    "The names for the centralities are:\n",
    "- ```PR```: PageRank centrality\n",
    "- ```CC```: Closeness Centrality\n",
    "- ```BC```: Betwenness centrality\n",
    "- ```LCC```: Local Clustering Coefficient\n",
    "\n",
    "For the approximation there is an integer value:\n",
    "- ```0```: exact centrality\n",
    "- ```1```: approximated centrality\n",
    "- ```2```: consider both the exact and the approximated centralities for comparison.\n",
    "\n",
    "The available metrics for visualization are:\n",
    "- ```P@5```, ```P@10``` , ```P@15```, ```P@20```: Precision at 5, 10, 15, 20\n",
    "- ```R@5```, ```R@10``` , ```R@15```, ```R@20```: Recall at 5, 10, 15, 20\n",
    "- ```P@tot```: the number of keywords divided by the number of nodes of the co-occurrence graph\n",
    "- ```R@tot```: the number of keywords effectively present in the abstract (hence, actually retrievable)\n",
    "\n",
    "Function ```significant_differences``` prints a boxplot of the selected metric for the centrality of choice and a table presenting the results of Tukey HSD multiple comparison test. This will help in assessing whether there is an actual difference in performance between the selected centralities. The confidence interval is set at 95% by default.\n",
    "\n",
    "Function ```average_metric``` outputs a simple DataFrame with the average performace (under a metric of choice) for all centralities. This is meant as an aid to better interpret the boxplots. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "commons.scores.significant_differences(['PR','CC','BC','LCC'], 2, 'R@20', run_name)\n",
    "display(commons.scores.average_metric('R@20', run_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
